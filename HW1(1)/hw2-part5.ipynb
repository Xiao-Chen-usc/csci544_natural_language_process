{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd60bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "### read the data \n",
    "fields = ['star_rating', 'review_body']\n",
    "\n",
    "test = pd.read_csv(\"amazon_reviews_us_Kitchen_v1_00.tsv\", sep = '\\t',usecols=fields,error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357cc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "### keep the balanced dataset \n",
    "### sample 50000 per star_rating from the data\n",
    "sample_size = 50000 ### here we use 10000 for testing \n",
    "df = test.groupby('star_rating').apply(lambda x: x.sample(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebaae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df.star_rating.apply(lambda x: 1 if x > 3.0 else( 2 if x < 3.0 else 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d62d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.rename(columns ={\"review_body\": \"review\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85e6f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-6d9c790aa9e0>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"review\"] = df[\"review\"].str.replace(r's*https?://S+(s+|$)', ' ').str.strip()\n",
      "<ipython-input-5-6d9c790aa9e0>:41: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"review\"] = df[\"review\"].str.replace('[^a-zA-Z]', ' ')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df[\"review\"] = df[\"review\"].astype(str)\n",
    "\n",
    "### Data cleaning and preprocssing \n",
    "df[\"review\"] = df[\"review\"].str.lower()\n",
    "\n",
    "## remove HTML \n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x :remove_tags(x))\n",
    "\n",
    "## remove URL\n",
    "df[\"review\"] = df[\"review\"].str.replace(r's*https?://S+(s+|$)', ' ').str.strip()\n",
    "\n",
    "def remove_extraS(text):\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: remove_extraS(x))\n",
    "\n",
    "def contractionfunction(phrase):\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: contractionfunction(x))\n",
    "\n",
    "## remove non-alphabetical characters\n",
    "df[\"review\"] = df[\"review\"].str.replace('[^a-zA-Z]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602aec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "df['review'] = df['review'].apply(word_tokenize)\n",
    "#df.head()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['review'] = df['review'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a049f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "pretrained_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78e94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841d103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57125b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review2tensor(x,model1=True):\n",
    "    ### we only need 50 reviews\n",
    "    max_review = 50\n",
    "    ### create a matrix \n",
    "    review = torch.zeros(max_review,1,300)\n",
    "    \n",
    "    index = 0\n",
    "    for word in x:\n",
    "       ### using pretrained model \n",
    "        if model1:\n",
    "            try:\n",
    "                vec = pretrained_model[word]\n",
    "                index += 1\n",
    "            except:\n",
    "                x.remove(word)  # exclude the non existing word from our vec \n",
    "                continue\n",
    "        else: # using my own model\n",
    "            try:\n",
    "                vec = w2v_model.wv[word]\n",
    "                index += 1\n",
    "                \n",
    "            except:\n",
    "                x.remove(word)\n",
    "                continue\n",
    "        \n",
    "        temp = torch.zeros(1, 300)\n",
    "        vec = torch.from_numpy(np.array(vec))\n",
    "        temp[0] = vec\n",
    "        ## if we have 50 reviews already break the loop \n",
    "        if index == max_review:\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            review[index-1][0] = temp\n",
    "            \n",
    "    final_tensor = torch.nan_to_num(review)\n",
    "        \n",
    "    return final_tensor \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a704ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.review.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "668c3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "the = review2tensor(b,model1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8244c5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 300])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711af1f",
   "metadata": {},
   "source": [
    "# Binary case : pretrained model (googel news 300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d77250e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df = df.loc[df[\"label\"] <3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d147709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 50\n",
    "n_label = 2\n",
    "\n",
    "rnn = RNN(300, n_hidden, n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b350d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare training\n",
    "def labelfromoutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return  category_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d527b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = binary_df[\"review\"].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b24c5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = review2tensor(b,model1=True)\n",
    "hidden= torch.zeros(1, n_hidden)\n",
    "output, next_hidden = rnn(input_[0], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "201ad8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[-0.7009, -0.6854]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(labelfromoutput(output))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9819e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    ### to prevent grandient explode\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(),0.5)\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "98a15f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-6ad3ccdd6d7f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  binary_df[\"label\"] = binary_df[\"label\"].apply(lambda x: 0 if x ==1 else 1)\n"
     ]
    }
   ],
   "source": [
    "binary_df[\"label\"] = binary_df[\"label\"].apply(lambda x: 0 if x ==1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "99ac02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list(zip(binary_df.review.values, binary_df.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "661a6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.shuffle(all_data)\n",
    "train_dataset, test_dataset = train_test_split(all_data, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd0a519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a97fb9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000,complete 3.125000%, 0m 37ss,the current averge loss is 0.700042\n",
      "10000,complete 6.250000%, 1m 13ss,the current averge loss is 0.709490\n",
      "15000,complete 9.375000%, 1m 50ss,the current averge loss is 0.722315\n",
      "20000,complete 12.500000%, 2m 26ss,the current averge loss is 0.732321\n",
      "25000,complete 15.625000%, 3m 3ss,the current averge loss is 0.740009\n",
      "30000,complete 18.750000%, 3m 39ss,the current averge loss is 0.747519\n",
      "35000,complete 21.875000%, 4m 14ss,the current averge loss is 0.763829\n",
      "40000,complete 25.000000%, 4m 49ss,the current averge loss is 0.820406\n",
      "45000,complete 28.125000%, 5m 24ss,the current averge loss is 0.948682\n",
      "50000,complete 31.250000%, 6m 0ss,the current averge loss is 1.050588\n",
      "55000,complete 34.375000%, 6m 35ss,the current averge loss is 1.130361\n",
      "60000,complete 37.500000%, 7m 10ss,the current averge loss is 1.192259\n",
      "65000,complete 40.625000%, 7m 45ss,the current averge loss is 1.238549\n",
      "70000,complete 43.750000%, 8m 20ss,the current averge loss is 1.270532\n",
      "75000,complete 46.875000%, 8m 55ss,the current averge loss is 1.295675\n",
      "80000,complete 50.000000%, 9m 30ss,the current averge loss is 1.311905\n",
      "85000,complete 53.125000%, 10m 5ss,the current averge loss is 1.327772\n",
      "90000,complete 56.250000%, 10m 40ss,the current averge loss is 1.340792\n",
      "95000,complete 59.375000%, 11m 19ss,the current averge loss is 1.352905\n",
      "100000,complete 62.500000%, 11m 56ss,the current averge loss is 1.362411\n",
      "105000,complete 65.625000%, 12m 34ss,the current averge loss is 1.371077\n",
      "110000,complete 68.750000%, 13m 12ss,the current averge loss is 1.376157\n",
      "115000,complete 71.875000%, 13m 49ss,the current averge loss is 1.382991\n",
      "120000,complete 75.000000%, 14m 25ss,the current averge loss is 1.393056\n",
      "125000,complete 78.125000%, 15m 0ss,the current averge loss is 1.400599\n",
      "130000,complete 81.250000%, 15m 35ss,the current averge loss is 1.403165\n",
      "135000,complete 84.375000%, 16m 11ss,the current averge loss is 1.406804\n",
      "140000,complete 87.500000%, 16m 45ss,the current averge loss is 1.410821\n",
      "145000,complete 90.625000%, 17m 21ss,the current averge loss is 1.412249\n",
      "150000,complete 93.750000%, 17m 56ss,the current averge loss is 1.414999\n",
      "155000,complete 96.875000%, 18m 31ss,the current averge loss is 1.418395\n",
      "160000,complete 100.000000%, 19m 6ss,the current averge loss is 1.420176\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "#### train using train dataset \n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "for whole_item in train_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    review_tensor = review2tensor(review, model1= True)\n",
    "    \n",
    "    \n",
    "    #category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(label_tensor, review_tensor)\n",
    "    current_loss += loss\n",
    "    index +=1 \n",
    "    ### \n",
    "    y_pred = labelfromoutput(output)\n",
    "    if y_pred  == label:\n",
    "        correct +=1 \n",
    "        \n",
    "    if index % 5000 == 0:\n",
    "        #print('%d %d%% (%s) %.4f ' % (index, index / len(train_dataset) * 100, timeSince(start), loss/5000))\n",
    "        #current_loss = 0\n",
    "        \n",
    "        print(\"{},complete {:4f}%, {}s,the current averge loss is {:4f}\".format(index,index/len(train_dataset)*100, timeSince(start),current_loss/index))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7010635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evalueating the result and get test accuracy \n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "n_label = 2\n",
    "confusion = torch.zeros(n_label, n_label)\n",
    "#n_confusion = 10000\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "      \n",
    "\n",
    "    return output\n",
    "\n",
    "for whole_item in test_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    review_tensor = review2tensor(review, model1= True)\n",
    "    output = evaluate(review_tensor)\n",
    "    \n",
    "    label_pred = labelfromoutput(output)\n",
    "    confusion[label][label_pred] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57d0f36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16908.,  3070.],\n",
       "        [ 5147., 14875.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### to calculate test accuracy using confusion table\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a4467d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the test accuracy from confusion table \n",
    "\n",
    "def accuracy_cf(table):\n",
    "    diagonal_sum = table.trace()\n",
    "    \n",
    "    sum_of_all_elements = table.sum()\n",
    "    \n",
    "    return diagonal_sum/sum_of_all_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "291061ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN : Binary Case with pretrained model (google news 300)| The Test Accuracy is 0.7945749759674072 \n"
     ]
    }
   ],
   "source": [
    "print(\"RNN : Binary Case with pretrained model (google news 300)| The Test Accuracy is {} \".format(accuracy_cf(confusion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e54b7f",
   "metadata": {},
   "source": [
    "# Tenary Case: pretrained_model (google_news_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b8254f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.0</th>\n",
       "      <th>3333330</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[unit, never, worked, gives, eo, message, appa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710317</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[gave, one, star, nothing, sticks, however, tu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674244</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[loved, microwave, loved, look, buttons, acros...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513833</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[way, smaller, thought, would, happy]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548916</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[kettle, waste, money, cord, attached, kettle,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5.0</th>\n",
       "      <th>2283852</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[exactly, looking, handles, x, easily, simple,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87780</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[strong, works, well, glad, purchased]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245030</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[finally, decent, set, pans, yahoo, pans, clea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744933</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[love, rice, cooker, replaced, basic, rice, co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756911</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[makes, juicing, citrus, breeze, easy, use, ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     star_rating  \\\n",
       "star_rating                        \n",
       "1.0         3333330          1.0   \n",
       "            2710317          1.0   \n",
       "            4674244          1.0   \n",
       "            513833           1.0   \n",
       "            3548916          1.0   \n",
       "...                          ...   \n",
       "5.0         2283852          5.0   \n",
       "            87780            5.0   \n",
       "            4245030          5.0   \n",
       "            744933           5.0   \n",
       "            2756911          5.0   \n",
       "\n",
       "                                                                review  label  \n",
       "star_rating                                                                    \n",
       "1.0         3333330  [unit, never, worked, gives, eo, message, appa...      2  \n",
       "            2710317  [gave, one, star, nothing, sticks, however, tu...      2  \n",
       "            4674244  [loved, microwave, loved, look, buttons, acros...      2  \n",
       "            513833               [way, smaller, thought, would, happy]      2  \n",
       "            3548916  [kettle, waste, money, cord, attached, kettle,...      2  \n",
       "...                                                                ...    ...  \n",
       "5.0         2283852  [exactly, looking, handles, x, easily, simple,...      1  \n",
       "            87780               [strong, works, well, glad, purchased]      1  \n",
       "            4245030  [finally, decent, set, pans, yahoo, pans, clea...      1  \n",
       "            744933   [love, rice, cooker, replaced, basic, rice, co...      1  \n",
       "            2756911  [makes, juicing, citrus, breeze, easy, use, ea...      1  \n",
       "\n",
       "[250000 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "61763da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y\"] = df[\"label\"].apply(lambda x: 0 if x ==1 else (1 if x==2 else 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3cd0b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ternary_data = list(zip(df.review.values, df.y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64949ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ternary_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "826a3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.shuffle(ternary_data)\n",
    "train_dataset, test_dataset = train_test_split(ternary_data, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8287ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 50\n",
    "n_label = 3\n",
    "\n",
    "rnn = RNN(300, n_hidden, n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "290e15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    ### to prevent grandient explode\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(),0.5)\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2db5a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000,complete:2.5%, 0m 37ss,the current averge loss is 1.063436\n",
      "10000,complete:5.0%, 1m 13ss,the current averge loss is 1.066940\n",
      "15000,complete:7.5%, 1m 49ss,the current averge loss is 1.067553\n",
      "20000,complete:10.0%, 2m 25ss,the current averge loss is 1.065846\n",
      "25000,complete:12.5%, 3m 2ss,the current averge loss is 1.068998\n",
      "30000,complete:15.0%, 3m 38ss,the current averge loss is 1.068099\n",
      "35000,complete:17.5%, 4m 14ss,the current averge loss is 1.068760\n",
      "40000,complete:20.0%, 4m 50ss,the current averge loss is 1.068945\n",
      "45000,complete:22.5%, 5m 26ss,the current averge loss is 1.067864\n",
      "50000,complete:25.0%, 6m 4ss,the current averge loss is 1.066530\n",
      "55000,complete:27.500000000000004%, 6m 40ss,the current averge loss is 1.065656\n",
      "60000,complete:30.0%, 7m 16ss,the current averge loss is 1.065141\n",
      "65000,complete:32.5%, 7m 52ss,the current averge loss is 1.064845\n",
      "70000,complete:35.0%, 8m 27ss,the current averge loss is 1.064866\n",
      "75000,complete:37.5%, 9m 3ss,the current averge loss is 1.065845\n",
      "80000,complete:40.0%, 9m 39ss,the current averge loss is 1.067859\n",
      "85000,complete:42.5%, 10m 14ss,the current averge loss is 1.069643\n",
      "90000,complete:45.0%, 10m 51ss,the current averge loss is 1.073044\n",
      "95000,complete:47.5%, 11m 30ss,the current averge loss is 1.079044\n",
      "100000,complete:50.0%, 12m 6ss,the current averge loss is 1.089048\n",
      "105000,complete:52.5%, 12m 42ss,the current averge loss is 1.152816\n",
      "110000,complete:55.00000000000001%, 13m 18ss,the current averge loss is 1.225141\n",
      "115000,complete:57.49999999999999%, 13m 53ss,the current averge loss is 1.287910\n",
      "120000,complete:60.0%, 14m 28ss,the current averge loss is 1.346126\n",
      "125000,complete:62.5%, 15m 4ss,the current averge loss is 1.394337\n",
      "130000,complete:65.0%, 15m 40ss,the current averge loss is 1.442206\n",
      "135000,complete:67.5%, 16m 15ss,the current averge loss is 1.482633\n",
      "140000,complete:70.0%, 16m 52ss,the current averge loss is 1.520428\n",
      "145000,complete:72.5%, 17m 30ss,the current averge loss is 1.554898\n",
      "150000,complete:75.0%, 18m 8ss,the current averge loss is 1.591815\n",
      "155000,complete:77.5%, 18m 45ss,the current averge loss is 1.621513\n",
      "160000,complete:80.0%, 19m 23ss,the current averge loss is 1.651702\n",
      "165000,complete:82.5%, 20m 0ss,the current averge loss is 1.680007\n",
      "170000,complete:85.0%, 20m 40ss,the current averge loss is 1.706359\n",
      "175000,complete:87.5%, 21m 20ss,the current averge loss is 1.731193\n",
      "180000,complete:90.0%, 21m 58ss,the current averge loss is 1.751409\n",
      "185000,complete:92.5%, 22m 34ss,the current averge loss is 1.770417\n",
      "190000,complete:95.0%, 23m 9ss,the current averge loss is 1.791042\n",
      "195000,complete:97.5%, 23m 45ss,the current averge loss is 1.807751\n",
      "200000,complete:100.0%, 24m 20ss,the current averge loss is 1.822665\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "#### train using train dataset \n",
    "current_loss = 0\n",
    "#all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "for whole_item in train_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    review_tensor = review2tensor(review, model1= True)\n",
    "    \n",
    "    \n",
    "    #category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(label_tensor, review_tensor)\n",
    "    current_loss += loss\n",
    "    index +=1 \n",
    "    ### \n",
    "    y_pred = labelfromoutput(output)\n",
    "    if y_pred  == label:\n",
    "        correct +=1 \n",
    "        \n",
    "    if index % 5000 == 0:\n",
    "        #print('%d %d%% (%s) %.4f ' % (index, index / len(train_dataset) * 100, timeSince(start), loss/5000))\n",
    "        #current_loss = 0\n",
    "        \n",
    "        print(\"{},complete:{}%, {}s,the current averge loss is {:4f}\".format(index,index/len(train_dataset)*100, timeSince(start),current_loss/index))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "67ea5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evalueating the result and get test accuracy \n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "n_label = 3\n",
    "confusion = torch.zeros(n_label, n_label)\n",
    "#n_confusion = 10000\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "      \n",
    "\n",
    "    return output\n",
    "\n",
    "for whole_item in test_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    review_tensor = review2tensor(review, model1= True)\n",
    "    output = evaluate(review_tensor)\n",
    "    \n",
    "    label_pred = labelfromoutput(output)\n",
    "    confusion[label][label_pred] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fcd44e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the test accuracy from confusion table \n",
    "\n",
    "def accuracy_cf(table):\n",
    "    diagonal_sum = table.trace()\n",
    "    \n",
    "    sum_of_all_elements = table.sum()\n",
    "    \n",
    "    return diagonal_sum/sum_of_all_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "de685d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14817.,  4790.,   358.],\n",
       "        [ 3382., 16416.,   368.],\n",
       "        [ 3982.,  5628.,   259.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "91badcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN : Ternary case with pretrained model : the Test Accuracy is  0.629840\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN : Ternary case with pretrained model : the Test Accuracy is  {:4f}\".format(accuracy_cf(confusion)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74f9cd9",
   "metadata": {},
   "source": [
    "# Binary Case : My Own word2vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "67df18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 50\n",
    "n_label = 2\n",
    "\n",
    "rnn = RNN(300, n_hidden, n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "91b3de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    ### to prevent grandient explode\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(),0.5)\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9e54956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list(zip(binary_df.review.values, binary_df.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b938ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.shuffle(all_data)\n",
    "train_dataset, test_dataset = train_test_split(all_data, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d556122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000,complete 3.125000%, 0m 36ss,the current averge loss is 0.701494\n",
      "10000,complete 6.250000%, 1m 12ss,the current averge loss is 0.727929\n",
      "15000,complete 9.375000%, 1m 48ss,the current averge loss is 0.728947\n",
      "20000,complete 12.500000%, 2m 24ss,the current averge loss is 0.728648\n",
      "25000,complete 15.625000%, 3m 0ss,the current averge loss is 0.724527\n",
      "30000,complete 18.750000%, 3m 37ss,the current averge loss is 0.739134\n",
      "35000,complete 21.875000%, 4m 12ss,the current averge loss is 0.785923\n",
      "40000,complete 25.000000%, 4m 48ss,the current averge loss is 0.915387\n",
      "45000,complete 28.125000%, 5m 23ss,the current averge loss is 1.025527\n",
      "50000,complete 31.250000%, 6m 0ss,the current averge loss is 1.124239\n",
      "55000,complete 34.375000%, 6m 38ss,the current averge loss is 1.197335\n",
      "60000,complete 37.500000%, 7m 15ss,the current averge loss is 1.254508\n",
      "65000,complete 40.625000%, 7m 53ss,the current averge loss is 1.291524\n",
      "70000,complete 43.750000%, 8m 30ss,the current averge loss is 1.313684\n",
      "75000,complete 46.875000%, 9m 8ss,the current averge loss is 1.333884\n",
      "80000,complete 50.000000%, 9m 48ss,the current averge loss is 1.346061\n",
      "85000,complete 53.125000%, 10m 27ss,the current averge loss is 1.361144\n",
      "90000,complete 56.250000%, 11m 4ss,the current averge loss is 1.368273\n",
      "95000,complete 59.375000%, 11m 39ss,the current averge loss is 1.375050\n",
      "100000,complete 62.500000%, 12m 15ss,the current averge loss is 1.381267\n",
      "105000,complete 65.625000%, 12m 50ss,the current averge loss is 1.382921\n",
      "110000,complete 68.750000%, 13m 26ss,the current averge loss is 1.384961\n",
      "115000,complete 71.875000%, 14m 1ss,the current averge loss is 1.387679\n",
      "120000,complete 75.000000%, 14m 37ss,the current averge loss is 1.389867\n",
      "125000,complete 78.125000%, 15m 12ss,the current averge loss is 1.389762\n",
      "130000,complete 81.250000%, 15m 48ss,the current averge loss is 1.386977\n",
      "135000,complete 84.375000%, 16m 23ss,the current averge loss is 1.386709\n",
      "140000,complete 87.500000%, 16m 59ss,the current averge loss is 1.388587\n",
      "145000,complete 90.625000%, 17m 35ss,the current averge loss is 1.387630\n",
      "150000,complete 93.750000%, 18m 10ss,the current averge loss is 1.386118\n",
      "155000,complete 96.875000%, 18m 46ss,the current averge loss is 1.388585\n",
      "160000,complete 100.000000%, 19m 21ss,the current averge loss is 1.390297\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "#### train using train dataset \n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "for whole_item in train_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    ## using my own word2vec model set model1 = False\n",
    "    review_tensor = review2tensor(review, model1= False)\n",
    "    \n",
    "    output, loss = train(label_tensor, review_tensor)\n",
    "    current_loss += loss\n",
    "    index +=1 \n",
    "    ### \n",
    "    y_pred = labelfromoutput(output)\n",
    "    if y_pred  == label:\n",
    "        correct +=1 \n",
    "        \n",
    "    if index % 5000 == 0:\n",
    "        #print('%d %d%% (%s) %.4f ' % (index, index / len(train_dataset) * 100, timeSince(start), loss/5000))\n",
    "        #current_loss = 0\n",
    "        \n",
    "        print(\"{},complete {:4f}%, {}s,the current averge loss is {:4f}\".format(index,index/len(train_dataset)*100, timeSince(start),current_loss/index))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "94fb3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evalueating the result and get test accuracy \n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "n_label = 2\n",
    "confusion = torch.zeros(n_label, n_label)\n",
    "#n_confusion = 10000\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "\n",
    "    return output\n",
    "\n",
    "for whole_item in test_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    ### set model1 = False to use my own word2vec model\n",
    "    review_tensor = review2tensor(review, model1= False)\n",
    "    output = evaluate(review_tensor)\n",
    "    \n",
    "    label_pred = labelfromoutput(output)\n",
    "    confusion[label][label_pred] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4a156e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17837.,  2130.],\n",
       "        [ 5213., 14820.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b27f722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Test Accuracy for binary case with my own model is 0.8164250254631042\n"
     ]
    }
   ],
   "source": [
    "print(\"the Test Accuracy for binary case with my own model is {}\".format(accuracy_cf(confusion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac132c99",
   "metadata": {},
   "source": [
    "# Ternary  Case : My own word2vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "94c2823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 50\n",
    "n_label = 3\n",
    "\n",
    "rnn = RNN(300, n_hidden, n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bac2ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    ### to prevent grandient explode\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(),0.5)\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d9ba7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.shuffle(ternary_data)\n",
    "train_dataset, test_dataset = train_test_split(ternary_data, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9ccf3146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000,complete 2.5%, 0m 35ss,each average current loss is 1.062224\n",
      "10000,complete 5.0%, 1m 11ss,each average current loss is 0.534274\n",
      "15000,complete 7.5%, 1m 47ss,each average current loss is 0.356569\n",
      "20000,complete 10.0%, 2m 22ss,each average current loss is 0.265135\n",
      "25000,complete 12.5%, 2m 58ss,each average current loss is 0.214100\n",
      "30000,complete 15.0%, 3m 34ss,each average current loss is 0.177453\n",
      "35000,complete 17.5%, 4m 10ss,each average current loss is 0.150625\n",
      "40000,complete 20.0%, 4m 46ss,each average current loss is 0.132481\n",
      "45000,complete 22.5%, 5m 21ss,each average current loss is 0.118327\n",
      "50000,complete 25.0%, 5m 56ss,each average current loss is 0.107954\n",
      "55000,complete 27.500000000000004%, 6m 32ss,each average current loss is 0.099036\n",
      "60000,complete 30.0%, 7m 7ss,each average current loss is 0.092669\n",
      "65000,complete 32.5%, 7m 43ss,each average current loss is 0.086807\n",
      "70000,complete 35.0%, 8m 18ss,each average current loss is 0.107239\n",
      "75000,complete 37.5%, 8m 53ss,each average current loss is 0.176162\n",
      "80000,complete 40.0%, 11m 56ss,each average current loss is 0.169711\n",
      "85000,complete 42.5%, 12m 33ss,each average current loss is 0.151920\n",
      "90000,complete 45.0%, 13m 8ss,each average current loss is 0.138936\n",
      "95000,complete 47.5%, 13m 44ss,each average current loss is 0.132012\n",
      "100000,complete 50.0%, 14m 19ss,each average current loss is 0.126951\n",
      "105000,complete 52.5%, 14m 55ss,each average current loss is 0.121418\n",
      "110000,complete 55.00000000000001%, 15m 30ss,each average current loss is 0.119601\n",
      "115000,complete 57.49999999999999%, 16m 6ss,each average current loss is 0.108603\n",
      "120000,complete 60.0%, 16m 41ss,each average current loss is 0.103421\n",
      "125000,complete 62.5%, 17m 17ss,each average current loss is 0.099308\n",
      "130000,complete 65.0%, 17m 56ss,each average current loss is 0.092234\n",
      "135000,complete 67.5%, 18m 34ss,each average current loss is 0.090566\n",
      "140000,complete 70.0%, 19m 11ss,each average current loss is 0.086668\n",
      "145000,complete 72.5%, 19m 49ss,each average current loss is 0.083108\n",
      "150000,complete 75.0%, 20m 27ss,each average current loss is 0.080095\n",
      "155000,complete 77.5%, 21m 5ss,each average current loss is 0.076083\n",
      "160000,complete 80.0%, 21m 45ss,each average current loss is 0.075987\n",
      "165000,complete 82.5%, 22m 22ss,each average current loss is 0.074513\n",
      "170000,complete 85.0%, 22m 58ss,each average current loss is 0.067941\n",
      "175000,complete 87.5%, 23m 34ss,each average current loss is 0.068061\n",
      "180000,complete 90.0%, 24m 12ss,each average current loss is 0.065912\n",
      "185000,complete 92.5%, 24m 49ss,each average current loss is 0.064065\n",
      "190000,complete 95.0%, 25m 26ss,each average current loss is 0.060656\n",
      "195000,complete 97.5%, 26m 3ss,each average current loss is 0.061658\n",
      "200000,complete 100.0%, 26m 41ss,each average current loss is 0.058553\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "#### train using train dataset \n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "for whole_item in train_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    ## using my own word2vec model set model1 = False\n",
    "    review_tensor = review2tensor(review, model1= False)\n",
    "    \n",
    "    output, loss = train(label_tensor, review_tensor)\n",
    "    current_loss += loss\n",
    "    index +=1 \n",
    "    ### \n",
    "    y_pred = labelfromoutput(output)\n",
    "    if y_pred  == label:\n",
    "        correct +=1 \n",
    "        \n",
    "    if index % 5000 == 0:\n",
    "        \n",
    "        print(\"{},complete {}%, {}s,each average current loss is {:4f}\".format(index,index/len(train_dataset)*100,\\\n",
    "                                                                             timeSince(start),current_loss/index))\n",
    "        \n",
    "        current_loss = 0 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "99b361df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evalueating the result and get test accuracy \n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "n_label = 3\n",
    "confusion = torch.zeros(n_label, n_label)\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "    return output\n",
    "\n",
    "for whole_item in test_dataset:\n",
    "    \n",
    "    label = whole_item[1]\n",
    "    review = whole_item[0]\n",
    "    #print(label)\n",
    "    label_tensor = torch.tensor([label],dtype =torch.long)\n",
    "    ### set model1 = False to use my own word2vec model\n",
    "    review_tensor = review2tensor(review, model1= False)\n",
    "    output = evaluate(review_tensor)\n",
    "    \n",
    "    label_pred = labelfromoutput(output)\n",
    "    confusion[label][label_pred] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "70d89d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17102.,  2775.,   133.],\n",
       "        [ 4448., 15434.,   216.],\n",
       "        [ 5132.,  4621.,   139.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e7c7c2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Test Accuracy for Ternary case with my own model is 0.653500\n"
     ]
    }
   ],
   "source": [
    "print(\"the Test Accuracy for Ternary case with my own model is {:4f}\".format(accuracy_cf(confusion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a094e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd71cd0d",
   "metadata": {},
   "source": [
    "# 5 B) GRU  Binary Case: pretrained model (google_news300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e7cadf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
